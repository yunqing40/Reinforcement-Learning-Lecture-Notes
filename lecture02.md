# Lecture 02 Markov Decision Processes

### 2.1 Introduction to MDP

* Environment is fully observable or assumed to be fully observable \(convert POMDP into MDP\)





