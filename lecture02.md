# Lecture 02 Markov Decision Processes

### 2.1 Introduction to MDP

* Environment is fully observable or assumed to be fully observable \(converting POMDP into MDP\)
* **Transition Probability** $$P_{ss'} = P(S_{t+1}=s' | P_t = s)$$ 
* **Transition Matrix** $$P = \begin{pmatrix} P_{11},P_{12}, ..., P_{1n} \\ ...\\ P_{n1},P_{n2}, ..., P_{nn}  \end{pmatrix}$$ 每行的概率加和为1
* **\[Def\] Markov Process** \(S,P\) where S is a finite set of states, and P is the transition matrix.
* 




